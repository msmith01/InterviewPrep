{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# https://www.hackerrank.com/contests/gs-codesprint-2018/challenges/car-popularity-prediction\n",
    "shhh <- suppressPackageStartupMessages\n",
    "# This code was written in base R as much as possible to be run on an external computer with a few exceptions.\n",
    "\n",
    "library(xgboost) # for the XGBoost model\n",
    "shhh(library(dplyr)) # for magrittr pipe functionality and dplyr mutatue functionality\n",
    "library(caret) # for confusionMatrix\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>buying_price</th><th scope=col>maintainence_cost</th><th scope=col>number_of_doors</th><th scope=col>number_of_seats</th><th scope=col>luggage_boot_size</th><th scope=col>safety_rating</th><th scope=col>popularity</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>3</td><td>2</td><td>4</td><td>2</td><td>2</td><td>2</td><td>1</td></tr>\n",
       "\t<tr><td>3</td><td>2</td><td>2</td><td>5</td><td>2</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>1</td><td>4</td><td>2</td><td>5</td><td>1</td><td>3</td><td>1</td></tr>\n",
       "\t<tr><td>4</td><td>4</td><td>2</td><td>2</td><td>1</td><td>2</td><td>1</td></tr>\n",
       "\t<tr><td>3</td><td>3</td><td>3</td><td>4</td><td>3</td><td>3</td><td>2</td></tr>\n",
       "\t<tr><td>2</td><td>1</td><td>2</td><td>2</td><td>1</td><td>1</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       " buying\\_price & maintainence\\_cost & number\\_of\\_doors & number\\_of\\_seats & luggage\\_boot\\_size & safety\\_rating & popularity\\\\\n",
       "\\hline\n",
       "\t 3 & 2 & 4 & 2 & 2 & 2 & 1\\\\\n",
       "\t 3 & 2 & 2 & 5 & 2 & 1 & 1\\\\\n",
       "\t 1 & 4 & 2 & 5 & 1 & 3 & 1\\\\\n",
       "\t 4 & 4 & 2 & 2 & 1 & 2 & 1\\\\\n",
       "\t 3 & 3 & 3 & 4 & 3 & 3 & 2\\\\\n",
       "\t 2 & 1 & 2 & 2 & 1 & 1 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| buying_price | maintainence_cost | number_of_doors | number_of_seats | luggage_boot_size | safety_rating | popularity |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 3 | 2 | 4 | 2 | 2 | 2 | 1 |\n",
       "| 3 | 2 | 2 | 5 | 2 | 1 | 1 |\n",
       "| 1 | 4 | 2 | 5 | 1 | 3 | 1 |\n",
       "| 4 | 4 | 2 | 2 | 1 | 2 | 1 |\n",
       "| 3 | 3 | 3 | 4 | 3 | 3 | 2 |\n",
       "| 2 | 1 | 2 | 2 | 1 | 1 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "  buying_price maintainence_cost number_of_doors number_of_seats\n",
       "1 3            2                 4               2              \n",
       "2 3            2                 2               5              \n",
       "3 1            4                 2               5              \n",
       "4 4            4                 2               2              \n",
       "5 3            3                 3               4              \n",
       "6 2            1                 2               2              \n",
       "  luggage_boot_size safety_rating popularity\n",
       "1 2                 2             1         \n",
       "2 2                 1             1         \n",
       "3 1                 3             1         \n",
       "4 1                 2             1         \n",
       "5 3                 3             2         \n",
       "6 1                 1             1         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>buying_price</th><th scope=col>maintainence_cost</th><th scope=col>number_of_doors</th><th scope=col>number_of_seats</th><th scope=col>luggage_boot_size</th><th scope=col>safety_rating</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>4</td><td>1</td><td>2</td><td>2</td><td>2</td><td>2</td></tr>\n",
       "\t<tr><td>2</td><td>1</td><td>3</td><td>4</td><td>3</td><td>2</td></tr>\n",
       "\t<tr><td>4</td><td>4</td><td>2</td><td>5</td><td>1</td><td>2</td></tr>\n",
       "\t<tr><td>4</td><td>3</td><td>3</td><td>2</td><td>2</td><td>2</td></tr>\n",
       "\t<tr><td>4</td><td>2</td><td>2</td><td>4</td><td>3</td><td>2</td></tr>\n",
       "\t<tr><td>4</td><td>3</td><td>5</td><td>2</td><td>3</td><td>3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " buying\\_price & maintainence\\_cost & number\\_of\\_doors & number\\_of\\_seats & luggage\\_boot\\_size & safety\\_rating\\\\\n",
       "\\hline\n",
       "\t 4 & 1 & 2 & 2 & 2 & 2\\\\\n",
       "\t 2 & 1 & 3 & 4 & 3 & 2\\\\\n",
       "\t 4 & 4 & 2 & 5 & 1 & 2\\\\\n",
       "\t 4 & 3 & 3 & 2 & 2 & 2\\\\\n",
       "\t 4 & 2 & 2 & 4 & 3 & 2\\\\\n",
       "\t 4 & 3 & 5 & 2 & 3 & 3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| buying_price | maintainence_cost | number_of_doors | number_of_seats | luggage_boot_size | safety_rating |\n",
       "|---|---|---|---|---|---|\n",
       "| 4 | 1 | 2 | 2 | 2 | 2 |\n",
       "| 2 | 1 | 3 | 4 | 3 | 2 |\n",
       "| 4 | 4 | 2 | 5 | 1 | 2 |\n",
       "| 4 | 3 | 3 | 2 | 2 | 2 |\n",
       "| 4 | 2 | 2 | 4 | 3 | 2 |\n",
       "| 4 | 3 | 5 | 2 | 3 | 3 |\n",
       "\n"
      ],
      "text/plain": [
       "  buying_price maintainence_cost number_of_doors number_of_seats\n",
       "1 4            1                 2               2              \n",
       "2 2            1                 3               4              \n",
       "3 4            4                 2               5              \n",
       "4 4            3                 3               2              \n",
       "5 4            2                 2               4              \n",
       "6 4            3                 5               2              \n",
       "  luggage_boot_size safety_rating\n",
       "1 2                 2            \n",
       "2 3                 2            \n",
       "3 1                 2            \n",
       "4 2                 2            \n",
       "5 3                 2            \n",
       "6 3                 3            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################################################################################################\n",
    "train_inSample <- read.csv(\"C:/Users/Matt/Desktop/Competitions/CarPopularity/train.csv\")\n",
    "test_outSample <- read.csv(\"C:/Users/Matt/Desktop/Competitions/CarPopularity/test.csv\")\n",
    "\n",
    "cols <- colnames(train_inSample)[-7]\n",
    "colnames(test_outSample) <- colnames(train_inSample[cols])\n",
    "\n",
    "head(train_inSample)\n",
    "head(test_outSample)\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>buying_price</th><th scope=col>maintainence_cost</th><th scope=col>number_of_doors</th><th scope=col>number_of_seats</th><th scope=col>luggage_boot_size</th><th scope=col>safety_rating</th><th scope=col>popularity</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>415</th><td>4</td><td>3</td><td>2</td><td>4</td><td>1</td><td>2</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>463</th><td>1</td><td>3</td><td>5</td><td>5</td><td>1</td><td>3</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>179</th><td>1</td><td>2</td><td>3</td><td>2</td><td>2</td><td>3</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>526</th><td>2</td><td>3</td><td>2</td><td>5</td><td>1</td><td>2</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>195</th><td>1</td><td>2</td><td>2</td><td>5</td><td>1</td><td>3</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>938</th><td>1</td><td>1</td><td>3</td><td>4</td><td>1</td><td>2</td><td>2</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       "  & buying\\_price & maintainence\\_cost & number\\_of\\_doors & number\\_of\\_seats & luggage\\_boot\\_size & safety\\_rating & popularity\\\\\n",
       "\\hline\n",
       "\t415 & 4 & 3 & 2 & 4 & 1 & 2 & 1\\\\\n",
       "\t463 & 1 & 3 & 5 & 5 & 1 & 3 & 2\\\\\n",
       "\t179 & 1 & 2 & 3 & 2 & 2 & 3 & 1\\\\\n",
       "\t526 & 2 & 3 & 2 & 5 & 1 & 2 & 1\\\\\n",
       "\t195 & 1 & 2 & 2 & 5 & 1 & 3 & 1\\\\\n",
       "\t938 & 1 & 1 & 3 & 4 & 1 & 2 & 2\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | buying_price | maintainence_cost | number_of_doors | number_of_seats | luggage_boot_size | safety_rating | popularity |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 415 | 4 | 3 | 2 | 4 | 1 | 2 | 1 |\n",
       "| 463 | 1 | 3 | 5 | 5 | 1 | 3 | 2 |\n",
       "| 179 | 1 | 2 | 3 | 2 | 2 | 3 | 1 |\n",
       "| 526 | 2 | 3 | 2 | 5 | 1 | 2 | 1 |\n",
       "| 195 | 1 | 2 | 2 | 5 | 1 | 3 | 1 |\n",
       "| 938 | 1 | 1 | 3 | 4 | 1 | 2 | 2 |\n",
       "\n"
      ],
      "text/plain": [
       "    buying_price maintainence_cost number_of_doors number_of_seats\n",
       "415 4            3                 2               4              \n",
       "463 1            3                 5               5              \n",
       "179 1            2                 3               2              \n",
       "526 2            3                 2               5              \n",
       "195 1            2                 2               5              \n",
       "938 1            1                 3               4              \n",
       "    luggage_boot_size safety_rating popularity\n",
       "415 1                 2             1         \n",
       "463 1                 3             2         \n",
       "179 2                 3             1         \n",
       "526 1                 2             1         \n",
       "195 1                 3             1         \n",
       "938 1                 2             2         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>buying_price</th><th scope=col>maintainence_cost</th><th scope=col>number_of_doors</th><th scope=col>number_of_seats</th><th scope=col>luggage_boot_size</th><th scope=col>safety_rating</th><th scope=col>popularity</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3</th><td>1</td><td>4</td><td>2</td><td>5</td><td>1</td><td>3</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>1</td><td>3</td><td>5</td><td>2</td><td>2</td><td>2</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>14</th><td>1</td><td>2</td><td>2</td><td>5</td><td>2</td><td>3</td><td>3</td></tr>\n",
       "\t<tr><th scope=row>15</th><td>2</td><td>4</td><td>2</td><td>2</td><td>3</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>22</th><td>4</td><td>4</td><td>4</td><td>2</td><td>1</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>23</th><td>3</td><td>1</td><td>2</td><td>5</td><td>1</td><td>1</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       "  & buying\\_price & maintainence\\_cost & number\\_of\\_doors & number\\_of\\_seats & luggage\\_boot\\_size & safety\\_rating & popularity\\\\\n",
       "\\hline\n",
       "\t3 & 1 & 4 & 2 & 5 & 1 & 3 & 1\\\\\n",
       "\t7 & 1 & 3 & 5 & 2 & 2 & 2 & 1\\\\\n",
       "\t14 & 1 & 2 & 2 & 5 & 2 & 3 & 3\\\\\n",
       "\t15 & 2 & 4 & 2 & 2 & 3 & 1 & 1\\\\\n",
       "\t22 & 4 & 4 & 4 & 2 & 1 & 1 & 1\\\\\n",
       "\t23 & 3 & 1 & 2 & 5 & 1 & 1 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | buying_price | maintainence_cost | number_of_doors | number_of_seats | luggage_boot_size | safety_rating | popularity |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 3 | 1 | 4 | 2 | 5 | 1 | 3 | 1 |\n",
       "| 7 | 1 | 3 | 5 | 2 | 2 | 2 | 1 |\n",
       "| 14 | 1 | 2 | 2 | 5 | 2 | 3 | 3 |\n",
       "| 15 | 2 | 4 | 2 | 2 | 3 | 1 | 1 |\n",
       "| 22 | 4 | 4 | 4 | 2 | 1 | 1 | 1 |\n",
       "| 23 | 3 | 1 | 2 | 5 | 1 | 1 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "   buying_price maintainence_cost number_of_doors number_of_seats\n",
       "3  1            4                 2               5              \n",
       "7  1            3                 5               2              \n",
       "14 1            2                 2               5              \n",
       "15 2            4                 2               2              \n",
       "22 4            4                 4               2              \n",
       "23 3            1                 2               5              \n",
       "   luggage_boot_size safety_rating popularity\n",
       "3  1                 3             1         \n",
       "7  2                 2             1         \n",
       "14 2                 3             3         \n",
       "15 3                 1             1         \n",
       "22 1                 1             1         \n",
       "23 1                 1             1         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################################################################################################\n",
    "################### Split the training data into 75% train and 25% validation #########################\n",
    "set.seed(123)\n",
    "train_validation_split = 0.75\n",
    "smp_size <- floor(train_validation_split * nrow(train_inSample))\n",
    "train_ind <- sample(seq_len(nrow(train_inSample)), size = smp_size)\n",
    "\n",
    "train <- train_inSample[train_ind, ]\n",
    "val <- train_inSample[-train_ind, ]\n",
    "\n",
    "head(train)\n",
    "head(val)\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>buying_price</th><th scope=col>maintainence_cost</th><th scope=col>number_of_doors</th><th scope=col>number_of_seats</th><th scope=col>luggage_boot_size</th><th scope=col>safety_rating</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>415</th><td>4</td><td>3</td><td>2</td><td>4</td><td>1</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>463</th><td>1</td><td>3</td><td>5</td><td>5</td><td>1</td><td>3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       "  & buying\\_price & maintainence\\_cost & number\\_of\\_doors & number\\_of\\_seats & luggage\\_boot\\_size & safety\\_rating\\\\\n",
       "\\hline\n",
       "\t415 & 4 & 3 & 2 & 4 & 1 & 2\\\\\n",
       "\t463 & 1 & 3 & 5 & 5 & 1 & 3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | buying_price | maintainence_cost | number_of_doors | number_of_seats | luggage_boot_size | safety_rating |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 415 | 4 | 3 | 2 | 4 | 1 | 2 |\n",
       "| 463 | 1 | 3 | 5 | 5 | 1 | 3 |\n",
       "\n"
      ],
      "text/plain": [
       "    buying_price maintainence_cost number_of_doors number_of_seats\n",
       "415 4            3                 2               4              \n",
       "463 1            3                 5               5              \n",
       "    luggage_boot_size safety_rating\n",
       "415 1                 2            \n",
       "463 1                 3            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>buying_price</th><th scope=col>maintainence_cost</th><th scope=col>number_of_doors</th><th scope=col>number_of_seats</th><th scope=col>luggage_boot_size</th><th scope=col>safety_rating</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3</th><td>1</td><td>4</td><td>2</td><td>5</td><td>1</td><td>3</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>1</td><td>3</td><td>5</td><td>2</td><td>2</td><td>2</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       "  & buying\\_price & maintainence\\_cost & number\\_of\\_doors & number\\_of\\_seats & luggage\\_boot\\_size & safety\\_rating\\\\\n",
       "\\hline\n",
       "\t3 & 1 & 4 & 2 & 5 & 1 & 3\\\\\n",
       "\t7 & 1 & 3 & 5 & 2 & 2 & 2\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | buying_price | maintainence_cost | number_of_doors | number_of_seats | luggage_boot_size | safety_rating |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 3 | 1 | 4 | 2 | 5 | 1 | 3 |\n",
       "| 7 | 1 | 3 | 5 | 2 | 2 | 2 |\n",
       "\n"
      ],
      "text/plain": [
       "  buying_price maintainence_cost number_of_doors number_of_seats\n",
       "3 1            4                 2               5              \n",
       "7 1            3                 5               2              \n",
       "  luggage_boot_size safety_rating\n",
       "3 1                 3            \n",
       "7 2                 2            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################################################################################################\n",
    "############ Split between x preditors and y prediction ############\n",
    "x_train <- train[, 1:6]\n",
    "x_val <- val[, 1:6] \n",
    "\n",
    "y_train <- train[, 7] - 1 # We -1 here since XGBoost can only take on labels in [0, num_class)\n",
    "y_val <- val[, 7] - 1\n",
    "\n",
    "head(x_train, 2)\n",
    "head(x_val, 2)\n",
    "head(y_train, 2)\n",
    "head(y_val, 2)\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb.DMatrix  dim: 1221 x 6  info: label  colnames: yes\n",
      "xgb.DMatrix  dim: 407 x 6  info: label  colnames: yes\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "# XGBoost xgb.DMatrix\n",
    "\n",
    "dtrain <- xgb.DMatrix(data = as.matrix(x_train), label = y_train, missing = \"NaN\")\n",
    "dval <- xgb.DMatrix(data = as.matrix(x_val), label = y_val, missing = \"NaN\")\n",
    "\n",
    "print(dtrain)\n",
    "print(dval)\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-mlogloss:1.231559+0.001356\ttest-mlogloss:1.233828+0.000110 \n",
      "Multiple eval metrics are present. Will use test_mlogloss for early stopping.\n",
      "Will train until test_mlogloss hasn't improved in 10 rounds.\n",
      "\n",
      "Stopping. Best iteration:\n",
      "[184]\ttrain-mlogloss:0.019723+0.000368\ttest-mlogloss:0.080088+0.009298\n",
      "\n",
      "[1]\ttrain-mlogloss:1.217302+0.001345\ttest-mlogloss:1.225348+0.000931 \n",
      "Multiple eval metrics are present. Will use test_mlogloss for early stopping.\n",
      "Will train until test_mlogloss hasn't improved in 10 rounds.\n",
      "\n",
      "Stopping. Best iteration:\n",
      "[112]\ttrain-mlogloss:0.019388+0.001568\ttest-mlogloss:0.104205+0.012344\n",
      "\n",
      "[1]\ttrain-mlogloss:1.216668+0.001290\ttest-mlogloss:1.221100+0.000891 \n",
      "Multiple eval metrics are present. Will use test_mlogloss for early stopping.\n",
      "Will train until test_mlogloss hasn't improved in 10 rounds.\n",
      "\n",
      "Stopping. Best iteration:\n",
      "[253]\ttrain-mlogloss:0.012736+0.000786\ttest-mlogloss:0.067186+0.008384\n",
      "\n",
      "[1]\ttrain-mlogloss:1.307780+0.002342\ttest-mlogloss:1.311593+0.000746 \n",
      "Multiple eval metrics are present. Will use test_mlogloss for early stopping.\n",
      "Will train until test_mlogloss hasn't improved in 10 rounds.\n",
      "\n",
      "Stopping. Best iteration:\n",
      "[344]\ttrain-mlogloss:0.021679+0.002403\ttest-mlogloss:0.100628+0.033729\n",
      "\n",
      "[1]\ttrain-mlogloss:1.301313+0.000858\ttest-mlogloss:1.304693+0.000411 \n",
      "Multiple eval metrics are present. Will use test_mlogloss for early stopping.\n",
      "Will train until test_mlogloss hasn't improved in 10 rounds.\n",
      "\n",
      "Stopping. Best iteration:\n",
      "[287]\ttrain-mlogloss:0.016760+0.000441\ttest-mlogloss:0.097298+0.014440\n",
      "\n",
      "[1]\ttrain-mlogloss:1.299636+0.000915\ttest-mlogloss:1.302688+0.000399 \n",
      "Multiple eval metrics are present. Will use test_mlogloss for early stopping.\n",
      "Will train until test_mlogloss hasn't improved in 10 rounds.\n",
      "\n",
      "Stopping. Best iteration:\n",
      "[251]\ttrain-mlogloss:0.018592+0.000857\ttest-mlogloss:0.085192+0.001879\n",
      "\n",
      "[1]\ttrain-mlogloss:0.956533+0.001960\ttest-mlogloss:0.966423+0.008998 \n",
      "Multiple eval metrics are present. Will use test_mlogloss for early stopping.\n",
      "Will train until test_mlogloss hasn't improved in 10 rounds.\n",
      "\n",
      "Stopping. Best iteration:\n",
      "[55]\ttrain-mlogloss:0.020598+0.000071\ttest-mlogloss:0.072632+0.005221\n",
      "\n",
      "[1]\ttrain-mlogloss:0.915874+0.003145\ttest-mlogloss:0.931581+0.006681 \n",
      "Multiple eval metrics are present. Will use test_mlogloss for early stopping.\n",
      "Will train until test_mlogloss hasn't improved in 10 rounds.\n",
      "\n",
      "Stopping. Best iteration:\n",
      "[82]\ttrain-mlogloss:0.012770+0.001448\ttest-mlogloss:0.082625+0.012943\n",
      "\n",
      "[1]\ttrain-mlogloss:0.910284+0.006792\ttest-mlogloss:0.929283+0.006012 \n",
      "Multiple eval metrics are present. Will use test_mlogloss for early stopping.\n",
      "Will train until test_mlogloss hasn't improved in 10 rounds.\n",
      "\n",
      "Stopping. Best iteration:\n",
      "[31]\ttrain-mlogloss:0.020365+0.001132\ttest-mlogloss:0.090162+0.023531\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  52.11   31.08   43.05 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The best parameters are:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>iter</th><th scope=col>train_mlogloss_mean</th><th scope=col>train_mlogloss_std</th><th scope=col>test_mlogloss_mean</th><th scope=col>test_mlogloss_std</th><th scope=col>MaxDepth</th><th scope=col>EtaValue</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>194      </td><td>0.0189685</td><td>0.0004235</td><td>0.080148 </td><td>0.00954  </td><td>5        </td><td>0.1      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       " iter & train\\_mlogloss\\_mean & train\\_mlogloss\\_std & test\\_mlogloss\\_mean & test\\_mlogloss\\_std & MaxDepth & EtaValue\\\\\n",
       "\\hline\n",
       "\t 194       & 0.0189685 & 0.0004235 & 0.080148  & 0.00954   & 5         & 0.1      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| iter | train_mlogloss_mean | train_mlogloss_std | test_mlogloss_mean | test_mlogloss_std | MaxDepth | EtaValue |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 194       | 0.0189685 | 0.0004235 | 0.080148  | 0.00954   | 5         | 0.1       |\n",
       "\n"
      ],
      "text/plain": [
       "  iter train_mlogloss_mean train_mlogloss_std test_mlogloss_mean\n",
       "1 194  0.0189685           0.0004235          0.080148          \n",
       "  test_mlogloss_std MaxDepth EtaValue\n",
       "1 0.00954           5        0.1     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The other parameters are:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>iter</th><th scope=col>train_mlogloss_mean</th><th scope=col>train_mlogloss_std</th><th scope=col>test_mlogloss_mean</th><th scope=col>test_mlogloss_std</th><th scope=col>MaxDepth</th><th scope=col>EtaValue</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>194      </td><td>0.0189685</td><td>0.0004235</td><td>0.080148 </td><td>0.00954  </td><td>5        </td><td>0.1      </td></tr>\n",
       "\t<tr><td>122     </td><td>0.018407</td><td>0.001464</td><td>0.104895</td><td>0.01255 </td><td>8       </td><td>0.1     </td></tr>\n",
       "\t<tr><td>263      </td><td>0.0125325</td><td>0.0007685</td><td>0.0672465</td><td>0.0082325</td><td>14       </td><td>0.1      </td></tr>\n",
       "\t<tr><td>354      </td><td>0.021161 </td><td>0.002279 </td><td>0.1007005</td><td>0.0346275</td><td>5        </td><td>0.05     </td></tr>\n",
       "\t<tr><td>297      </td><td>0.0164475</td><td>0.0003705</td><td>0.097382 </td><td>0.014646 </td><td>8        </td><td>0.05     </td></tr>\n",
       "\t<tr><td>261      </td><td>0.0181415</td><td>0.0008235</td><td>0.085277 </td><td>0.001917 </td><td>14       </td><td>0.05     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       " iter & train\\_mlogloss\\_mean & train\\_mlogloss\\_std & test\\_mlogloss\\_mean & test\\_mlogloss\\_std & MaxDepth & EtaValue\\\\\n",
       "\\hline\n",
       "\t 194       & 0.0189685 & 0.0004235 & 0.080148  & 0.00954   & 5         & 0.1      \\\\\n",
       "\t 122      & 0.018407 & 0.001464 & 0.104895 & 0.01255  & 8        & 0.1     \\\\\n",
       "\t 263       & 0.0125325 & 0.0007685 & 0.0672465 & 0.0082325 & 14        & 0.1      \\\\\n",
       "\t 354       & 0.021161  & 0.002279  & 0.1007005 & 0.0346275 & 5         & 0.05     \\\\\n",
       "\t 297       & 0.0164475 & 0.0003705 & 0.097382  & 0.014646  & 8         & 0.05     \\\\\n",
       "\t 261       & 0.0181415 & 0.0008235 & 0.085277  & 0.001917  & 14        & 0.05     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| iter | train_mlogloss_mean | train_mlogloss_std | test_mlogloss_mean | test_mlogloss_std | MaxDepth | EtaValue |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 194       | 0.0189685 | 0.0004235 | 0.080148  | 0.00954   | 5         | 0.1       |\n",
       "| 122      | 0.018407 | 0.001464 | 0.104895 | 0.01255  | 8        | 0.1      |\n",
       "| 263       | 0.0125325 | 0.0007685 | 0.0672465 | 0.0082325 | 14        | 0.1       |\n",
       "| 354       | 0.021161  | 0.002279  | 0.1007005 | 0.0346275 | 5         | 0.05      |\n",
       "| 297       | 0.0164475 | 0.0003705 | 0.097382  | 0.014646  | 8         | 0.05      |\n",
       "| 261       | 0.0181415 | 0.0008235 | 0.085277  | 0.001917  | 14        | 0.05      |\n",
       "\n"
      ],
      "text/plain": [
       "  iter train_mlogloss_mean train_mlogloss_std test_mlogloss_mean\n",
       "1 194  0.0189685           0.0004235          0.080148          \n",
       "2 122  0.018407            0.001464           0.104895          \n",
       "3 263  0.0125325           0.0007685          0.0672465         \n",
       "4 354  0.021161            0.002279           0.1007005         \n",
       "5 297  0.0164475           0.0003705          0.097382          \n",
       "6 261  0.0181415           0.0008235          0.085277          \n",
       "  test_mlogloss_std MaxDepth EtaValue\n",
       "1 0.00954           5        0.1     \n",
       "2 0.01255           8        0.1     \n",
       "3 0.0082325         14       0.1     \n",
       "4 0.0346275         5        0.05    \n",
       "5 0.014646          8        0.05    \n",
       "6 0.001917          14       0.05    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################################################################################################\n",
    "# Grid Search Parameters (very simplistic model for this test - I omit many of the XGBoost parameters due to time constraints):\n",
    "# 1)\n",
    "ParameterGridSearch <- expand.grid(max_depth = c(5, 8, 14), #Range (0, inf], default = 6\n",
    "                                eta = c(0.1, 0.05, 0.3) #Range (0,1], default = 0.3\n",
    "                                )\n",
    "\n",
    "\n",
    "ntrees = 2\n",
    "nrounds = 1500\n",
    "early_stopping_rounds = 10\n",
    "numberOfClasses = as.numeric(length(unique(y_train)))\n",
    "\n",
    "# Search over a grid space to locate the most optimal parameters.\n",
    "# 2)\n",
    "system.time(\n",
    "  Hyperparameters <- apply(ParameterGridSearch, 1, function(parameterList){\n",
    "    MaxDepth = parameterList[[\"max_depth\"]]\n",
    "    EtaValue = parameterList[[\"eta\"]]\n",
    "    \n",
    "    xgb_params <- list(\"objective\" = \"multi:softprob\", # multi probabilistic classification\n",
    "                       \"eval_metric\" = \"mlogloss\",\n",
    "                       \"num_class\" = numberOfClasses,\n",
    "                       \"max_depth\" = MaxDepth,\n",
    "                       \"eta\" = EtaValue)\n",
    "    \n",
    "    xgboostModelCV <- xgb.cv(params = xgb_params,\n",
    "                             data =  dtrain,\n",
    "                             nfold = ntrees,\n",
    "                             nrounds = nrounds,\n",
    "                             early_stopping_rounds = early_stopping_rounds,\n",
    "                             seed = 1234,\n",
    "                             prediction = TRUE,\n",
    "                             print_every_n = 500) # To save on output space in the ipynb file\n",
    "    \n",
    "    CrossValidationResults <<- as.data.frame(xgboostModelCV$evaluation_log)\n",
    "    BestIteration = tail(CrossValidationResults, 1)\n",
    "    EvaluationResults = return(c(BestIteration, MaxDepth, EtaValue))\n",
    "    }\n",
    "  )\n",
    ")\n",
    "\n",
    "CVResults <- as.data.frame(do.call(rbind, Hyperparameters))\n",
    "\n",
    "# Find the best iteration by test_mlogloss and train_mlogloss\n",
    "names(CVResults)[names(CVResults) == 'V6'] <- 'MaxDepth'\n",
    "names(CVResults)[names(CVResults) == 'V7'] <- 'EtaValue'\n",
    "print(\"The best parameters are:\")\n",
    "CVResults[with(CVResults, order(\"test_mlogloss_mean\", \"train_mlogloss_mean\")), ]\n",
    "\n",
    "print(\"The other parameters are:\")\n",
    "head(CVResults)\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAV1BMVEUAAAAXFxcqKio8PDxN\nTU1dXV1oaGhtbW18fHyMjIyampqbm5unp6eqqqqysrK4uLi9vb2+vr7GxsbHx8fQ0NDT09PV\n1dXZ2dnh4eHi4uLp6enw8PD////j39XaAAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4\nnO3cjXbiSJKG4axuNQUMw7Jlb+MC3f91rn5A6AdwSRlJRBLvc854ZCTC6sz4xmHZPaEEEC1o\n3wDwDggSIIAgAQIIEiCAIAECCBIggCABAggSIIAgAQIIEiCAIAECCBIggCABAggSIIAgAQII\nEiCAIAECCBIggCABAggSIIAgAQIIEiCAIAECCBIggCABAggSIIAgAQIIEiCAIAECCBIggCAB\nAggSIIAgAQIIEiCAIAECCBIggCABAggSIIAgAQIIEiCAIAECCBIggCABAggSIIAgAQIIEiCA\nIAECCBIggCABAggSIIAgAQIIEiCAIAECCBIggCABAggSIIAgAQIIEiCAIAECCBIggCABAggS\nIIAgAQIIEiCAIAECCBIggCABAggSIIAgAQIIEiCAIAECCBIggCABAggSIIAgAQIIEiCAIAEC\nCBIggCABAggSIIAgAQIIEiCAIAECCBIggCABAggSIIAgAQIIEiCAIAECCBIggCABAggSIIAg\nAQIIEiCAIAECCBIggCABAggSIIAgAQJ8Bun/8qma0a3mVFW8KEEyXjWjW82pKkECLCJIgACf\nQfI8g1A1SVGCZLxqRreaU1WCBFhEkAABPoPkeQahapKiBMl41YxuNaeqBAmwiCABAnwGyfMM\nQtUkRQmS8aoZ3WpOVQkSYBFBAgT4DJLnGYSqSYoSJONVM7rVnKoSJMAiggQI8BkkzzMIVZMU\n9Rmk/wWeWNBSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkY\nW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkY\nW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkY\nW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkYW9BSBAkY\nW9BSNoJ0Woewun16KP7sbc11YcE/gvZGwbb5HWUkSEUI/Tz8aTaa6wgSpM3vKCNBGoVhVpCW\n0N4o2LagpTSCtC/C6lAfHDchFLs6EM03pPM2hO25/fTcjnrn/sRXnfgq1sO3tWkK4bRpXmqm\nxNXndwnT3ijYtqCpFYK0a3JTJemzOQi7a5CaAW91CcgufFbXfoR9/2bDOmyHb7sGqWhfKs9F\nCMM58R7tjYJtC7paIUjVt4/yGIqyXIWPsvy6hqHc10HY1QmrP/0K1feechOOg3fW33RGb2sP\n1ufyUNfcV287rwkSYizp6gXviVSE7efl8PS5X3eJWDX3EjaXTzfhqzoaPL+rIzh522W0uxyt\n6qMTQUKMBV2tEKTPavpaNYlYX8ewSyIGn35VkfqsJrn+zbZ3O37b9cTw6BntjYJtC7pa5and\n1yoU1ci2DavD5+lRkOpvLu0PSrebbV6fvI0gQdaCnlZ6/H3omv48Gu2am2qOPsOuuPdYfPS2\nYXwY7RBvQUer/Ix0rOa2om784+XBQNP4u/pRwkf9jOGSg1VoHjj0bvaSl8HbhkHa1W/hYQOi\nLOhqtcff++vB7XtT++T6q3maXV/4Gernc/2bDbf3X556j4PE42/EW9DVGqNdNbEVza+HttW3\nnOMtCKfm87JsH2SXt6d0V5d8dG87TIPU/EL2gyAhxoKmtvEnQvcdB3/WMEf45q9etTcKti1p\nuUWN+hrr4TO7P1L/AFUNf9vnV2lvFGxb0Kx2gxQujxpCuD0X/97lB6jT86u0Nwq2LWnXBe95\njaL+G4dybpDKwyqE7Tc5Ikh4akG72g1SStobBdsWtBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYW\ntBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYW\ntBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYW\ntBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYWtBRBAsYWtJTPIAHCfAbp//KpmtGt5lRV\nvChBMl41o1vNqSpBAiwiSIAAn0HyPINQNUlRgmS8aka3mlNVggRYRJAAAT6D5HkGoWqSogTJ\neNWMbjWnqgQJsIggAQJ8BsnzDELVJEUJkvGqGd1qTlUJEmCRzyBp/4tjrmlvfhoECS82d7MY\n7ezS7iXX5m4WQbJLu5dc0978NAgSXkx789MgSHixuZvFaGeXdi+5NnezCJJd2r3kmvbmp0GQ\n8GLam58GQcKLzd0sRju7tHvJtbmbRZDs0u4l17Q3Pw2ChBfT3vw0CBJebO5mMdrZpd1Lrs3d\nLIJkl3Yvuaa9+WkQJLyY9uanQZDwYnM3i9HOLu1ecm3uZhEku7R7yTXtzU+DIOHFtDc/DYKE\nF5u7WYx2dmn3kmtzN4sg2aXdS65pb34aBAkvpr35aRAkvNjczWK0s0u7l1ybu1kEyS7tXnJN\ne/PTIEh4Me3NT4Mg4cXmbhajnV3aveTa3M0iSHZp95Jr2pufBkHCi2lvfhoECS82d7MY7ezS\n7iXX5m4WQbJLu5dc0978NF4fpDDrS57WIaz+8NpD8adVtXvJtTnbnw/rQSpC+OM3/Hll7V5y\nbc721xjtHnzFWV9yztUEKQtztr/mM0ghnDah2JXXtq4/Vv/ZhE15WoXN+fLZ+lSfPG9D2J6b\nq76Kdb/MqT5zqk+MviHti7A6DN5bHjeh+YqXS7srntDuJddkGs0a+SA1w9huGKSq1cPHqvqw\nvX5W1BloLl01V63rU51zc6a6ZhykXfPCof/ez+al6iu2l96ueEK7l1yTbTgr5IO0PpeHUAyD\ntC0/6lb/aD+rrljXUdvXH3Z10zfJ69mF6vvT+hbHXvlTeayr3967Ch9l+XX5zte74hntXnJt\nbku5He3KbqDrjpoh7dz77FR/M1m1V2yu77pZddeMglSE7efliut7qws/9+vuK3ZXPKPdS67N\nbSmvQbp+HB11H/qvh8voNn5MMK7S+awmulUb1et7q+9c/SrdFc9o95Jr0T1mUmZBqoa4VSiO\n/fduw+rweepde7niGe1eci22xWxKHKTTvSANR7vbu24ejna1Q/3a6L3nQegO3z0I1+4l1+a2\nlPfRrggf5Xl9L0jr+vV9/axgV5Yf9XOFceM/fNhQhGP5VT9K6L/32P863RXPaPeSa3NbynuQ\nmufQ+3tBuj7+bh9yh69pkLrH3+Mz7cPtff+9u96AWPSueEa7l1wT7DZD0gWp3BVVP9/9GWkT\nNs3jgPrXrutjeWeAu/5Cdvq9qgjFfvDesjmor2ueut+ueEK7l1yLazCr+OtvvNjczfI52uVB\nu5dcm7tZBGmmEG7PtP/sxGLaveSa1CbaQpDwYlKbaIuhIL2Qdi+5NnezGO3s0u4l1+ZuFkGy\nS7uXXNPe/DQIEl5Me/PTIEh4sbmbxWhnl3YvuTZ3swiSXdq95Jr25qdBkPBi2pufBkHCi83d\nLEY7u7R7ybW5m0WQ7NLuJde0Nz8NgoQX0978NAgSXmzuZjHa2aXdS67N3SyCZJd2L7mmvflp\nECS8mPbmp0GQ8GJzN4vRzi7tXnJt7mYRJLu0e8k17c1PgyDhxbQ3Pw2ChBebu1mMdnZp95Jr\nczeLINml3UuuaW9+GgQJL6a9+WkQJLzY3M1itLNLu5dcm7tZBMku7V5yTXvz0yBIeDHtzU+D\nIOHF5m4Wo51dSfYmkx2napKiPoMECCNIgACfQfI8g1A1SVGCZLxqRreaU1WCBFhEkAABPoPk\neQahapKiBMl41YxuNaeqBAmwiCABAnwGyfMMQtUkRQmS8aoZ3WpOVQkSYBFBAgT4DJLnGYSq\nSYr6DJL2v9tmVOyyEiRvtDvWKO1tyRlBQkd7W3JGkNCJXVZGO2+0O9ao2GUlSN5od6xR2tuS\nM4KEjva25IwgoRO7rIx23mh3rFGxy0qQvNHuWKO0tyVnBAkd7W3JGUFCJ3ZZGe280e5Yo2KX\nlSB5o92xRmlvS84IEjra25IzgoRO7LIy2nmj3bFGxS4rQfJGu2ON0t6WnBEkdLS3JWcECZ3Y\nZWW080a7Y42KXVaC5I12xxqlvS05I0joaG9LzggSOrHLymjnjXbHGhW7rATJG+2ONUp7W3JG\nkNDR3pacESR0YpeV0c4b7Y41KnZZCZI32h1rlPa25IwgoaO9LTkjSOjELiujnTfaHWtU7LIS\nJG+0O9Yo7W3JGUFCR3tbckaQ0IldVka7RMKg+qF4clLU6CtNaXesUbHrTpASGWZllJyEQfq2\ntHbHGpVsQxx44WiXMDlzv5J2xxr1ks15UyLNXTXuJmzK0ypsztWnx00Ixa59vfrPadN8FkLT\n3/dPluV5G8L2XA5em57suV1VnzzVR/sirA7dV3pCu2ONiu0DRrvYIqFKR/hYVR+2ZfkZGrtr\nVor2s7a9H5wsy+ZgVfZfOzcHm/7Jm+5ke1BUMds1pQ8EaanYPiBIsUWq/HzUvf9Rd/AqfJTl\nV5uT+j/rc3kIxWXgenRyXydnFw7913ZV2WN92e3kTXdyF9ZluW6jeapeKhjtlpLoBa+EgnSq\nP5yvLXz63K9vWTmV16Py8clVc7L+DtN/7TLN3U7e9E5W15/q71dF2H5e7uebG9buWKMkesEr\nqZ+R+h/W7fjWj8/t6OHJ/uuD5PVPjr7m7aAZG6shb3UqCdJSsX3AaBdbZBCkbfUT/+fpQZAe\nn4wPUjUzrkJxJEhLxfYBQYotMghSc3B+EKRHJ1dhUOzeaDd0Z7SrHQYJfES7Y41auv9IFKRj\neV4/DNL9k7v6acFH/dxg+NrX8ORN7+T1YUNR1f7iYcNyEr3gVYIg7cKjH4OKxyfbh9jhq//a\n6frU+3byZnTy9vh7f/lKz2h3rFGxfcBoF1tk+LBhG8L6OM1K80j70cnm16rrYzl47Wt9+VVr\nd7JncLL9heyuCEWVo8tXekK7Y42K7QOC5I12xxqlvS05I0joaG9LzvIKUujE1dHuWKNit4fR\nLhcEKanY7SFI3mh3rFHa25IzgoSO9rbkjCChE7usjHbeaHesUbHLSpC80e5Yo7S3JWcECR3t\nbckZQUIndlkZ7bzR7lijYpeVIHmj3bFGaW9LzggSOtrbkjOChE7ssjLaeaPdsUbFLitB8ka7\nY43S3pacESR0tLclZwQJndhlZbTzRrtjjYpdVoLkjXbHGqW9LTkjSOhob0vOCBI6scvKaOeN\ndscaFbusBMkb7Y41SntbckaQ0NHelpwRJHRil5XRzhvtjjUqdlkJkjfaHWuU9rbkjCCho70t\nOSNI6MQuK6OdN9oda1TsshIkb7Q71ijtbcmZzyABwnwGyfMMQtUkRQmS8aoZ3WpOVQkSYBFB\nAgT4DJLnGYSqSYoSJONVM7rVnKoSJMAiggQI8BkkzzMIVZMUJUjGq2Z0qzlVJUiARQQJEOAz\nSJ5nEKomKUqQjFfN6FZzqkqQAIsIEiDAZ5C0/1VUE+SXldHOG+0eNkF+WQmSN9o9bIL2JrwX\nguSW9ia8F4LklvyyMtp5o93DJsgvK0HyRruHTdDehPdCkNzS3oT3QpDckl9WRjtvtHvYBPll\nJUjeaPewCdqb8F4Iklvam/BeCJJb8svKaOeNdg+bIL+sBMkb7R42QXsT3gtBckt7E94LQXJL\nflkZ7bzR7mET5JeVIHmj3cMmaG/CeyFIbmlvwnshSG7JLyujnTfaPWyC/LISJG+0e9gE7U14\nLwTJLe1NeC8EyS35ZWW080a7h02QX1aC5I12D5ugvQnvhSC5pb0J74UguSW/rIx23mj3sAny\ny0qQvNHuYRO0N+G9ECS3tDfhvRAkt+SXldHOG+0eNkF+WQmSN9o9bIL2JrwXguSW9ia8F40g\nhWdf9OlJoXcQpNrsVfsWo91rESQTZq/atwjSay3ofGHaPWyC9ia8F6UgbcL6VF4jFcI5rOqD\n+r/ql0I4bUKxq186rcPqc5i8/tu/inVbpHvDeRvC9vzNHWj3sAnS2+qbTpA2IYTifAtSuQuf\n1cFH2F+CVFQXhCoY5+ZgHKRt9/Z12DbvaK/bVGebg9U3d6DdwybIbyyj3WtV/X8u13VOuiB9\nhXV1sAnHS5CqCw6hKMt99fp5PQ7S7e279u1VELflsT7Y1y/twuH5HWj3sAnyG0uQXqua3KpZ\nrP620QWpytBXdVCU19Hu8vKqvXQUpK/u7bfrLtPcqq24eX4H2j1sgvzGeqb3sKFNzPXoq+r9\nz+rbyujl29Hzt3dXhDCdBae0e9gEwR2FmSDV33uaH5QI0qvIbegVo91rjUa7dnL7DLsilOOA\n3B/tmtfWw+sGo913tHvYBMEdvSBIrxXaJwj7+hHbR/csYRWaBw7DIO3q16YPGy5v71+3q6bD\ny0H50VR6QruHTUiyt27pPv7e1VPYvs3DZ6hSNQ7S/cff6/rtZf+60/Wp9+UNX8/vQLuHTUix\ntX6p/UJ2Uz9wK6txbn/9Aef2DK73k1H9C9mPyWi3Dtv+73OrD19VuJrXTtsqaMdv7kC7h00Q\n3dMGo50Fx8e/Rm2+/dw+i79n7R42IXoVJwiSBevmjxtGQji2v20dvBb9tbR72IToVUSPlSCF\ncPcBwa79EenUPdauUkSQZESvInqsBKl48McIh1X7sw9BEhe9ihOMdt5o97AJ8stKkLzR7mET\ntDfhvRAkt7Q34b0QJLfkl5XRzhvtHjZBflkJkjfaPWyC9ia8F4LklvYmvBeC5Jb8sjLaeaPd\nwybILytB8ka7h03Q3oT3QpDc0t6E90KQ3JJfVkY7b7R72AT5ZSVI3mj3sAnam/BeCJJb2pvw\nXgiSW/LLymjnjXYPmyC/rATJG+0eNkF7E94LQXJLexPeC0FyS35ZGe280e5hE+SXlSB5o93D\nJmhvwnshSG5pb8J7IUhuyS8ro5032j1sgvyyEiRvtHvYBO1NeC8EyS3tTXgvBMkt+WVltPNG\nu4dNkF9WggQgCkECBPgMkucZhKpJihIk41UzutWcqhIkwCKCBAjwGSTPMwhVkxQlSMarZnSr\nOVUlSIBFBAkQ4DNInmcQqiYpSpCMV83oVnOqSpAAiwgSIMBnkDzPIFRNUpQgGa+a0a3mVJUg\nidD+d+oiaS8fpghShrSXD1MEKUPxC5DREMZoZ5h2EiLFL0BGLU+QDNNOQiTt5cMUQcqQ9vJh\niiBlKH4BMhrCGO0M005CpPgFyKjlCZJh2kmIpL18mCJIGdJePkwRpAzFL0BGQxijnWHaSYgU\nvwAZtTxBMkw7CZG0lw9TBClD2suHKYKUofgFyGgIY7QzTDsJkeIXIKOWJ0iGaSchkvbyYYog\nZUh7+TBFkDIUvwAZDWGMdoZpJyFS/AJk1PIEyTDtJETSXj5MEaQMaS8fpghShuIXIKMhjNHO\nMO0kRIpfgIxaniAZpp2ESNrLhymClCHt5cMUQcpQ/AJkNIQx2hmmnYRI8QuQUcsTJMO0kxBJ\ne/kwRZAypL18mCJIGYpfgIyGMEY7w7STECl+ATJqeYJkmHYSImkvH6YIUoa0lw9TBClD8QuQ\n0RDGaGeYdhIixS9ARi3vKEhBLI3PKx0Kqa+vnYRIc/9xkV5OQXp0liBB3TsEaT7tJESKX4CM\nhjBno13b5M3H0zqsPkdHx00Ixa4cvHbehrA9jyttwvrUXFefHRyFMErSvgirQ/uucHG36pR2\nEiLFb1lGLe82SOei6+nu6LM92PVfK5uj1ahSFbhQnK/XDY7GQdo1hQ6jIN2pOqWdhEgCewZh\n8kHah3V5Xg+PVuGjLL/GZ3d1GA7DSutzuW5PrMvx0egbUgin8hiK2+vr6sp7Vae0kxBJYM8g\nTD5Iq6q/y9PwqPqvz/16fLZ5x2ZYqTm76q4bHI2CVITtZ/f1yzZHd6tOaSchUvyWZTSEuR3t\n7h1VTX6ZvPpnuyFvUOm7ep3Paopbna7vOjc5ult1SjsJkSL3q8yq5QlS72gbVofPk3CQqmFx\nFYpj+/qp+v7UXkeQoEA0SKOB7nbUfs+4N9qNK80Y7WqHS/UqR80zwbtVp7STEClms5CGVJCK\n8HF5iHB5ODA4CuF452zV+h/NPNar1DyK2P/Rw4aiKvp1edhwzdHdqlPaSYgUv2UZDWHORrvm\nWfT+0ePvXZi+djn6GlZ68vi7Ojv4G6G26H74+Pte1SntJESK37KMWt5ZkMpdUfV092vYj9HR\ntvpecxyfbV4cV9qEzYNfyFZz3PCP7aovWezL0e+R7lSd0k5CJIE9gzCxv7oZ1y2mR/fO6tBO\nQiTdxcM98kGqfx6qxq5t/+jeWU3aSYgUvwAZDWGORruhy89Dp/7RvbO3Wwi3wexbsy5+SDsJ\nkWL+0VsZtbzbIJWH1fWnm9vRvbPdLRCkmWL+0ZFGqp+RbNNOQiTt5cMUQcpQ/AJkNIT5He0y\noJ2ESPELkFHLEyTDtJMQSXv5MEWQMqS9fJgiSBmKX4CMhjBGO8O0kxApfgEyanmCZJh2EiJp\nLx+mCFKGtJcPUwQpQ/ELkNEQxmhnmHYSIsUvQEYtT5AM005CJO3lwxRBypD28mGKIGUofgEy\nGsIY7QzTTkKk+AXIqOUJkmHaSYikvXyYIkgZ0l4+TBGkDMUvQEZDGKOdYdpJiBS/ABm1PEEy\nTDsJkbSXD1MEKUPay4cpgpSh+AXIaAhjtDNMOwmR4hcgo5YnSIZpJyGS9vJhiiBlSHv5MEWQ\nMhS/ABkNYYx2hmknIVL8AmTU8gTJMO0kRNJePkwRpAxpLx+mfAbJ8wxC1SRFCZLxqhndak5V\nCRJgEUECBPgMkucZhKpJihIk41UzutWcqhIkwCKCBAjwGSTPMwhVkxQlSMarZnSrOVUlSIBF\nBAkQ4DNInmcQqiYpSpCMV83oVnOqSpAAiwgSIMBnkNL8O3V5zCBUTVKUIBEkj1UJkog0QYJj\nBIkgQQBBkgtSHjMIVZMUJUgEyWNVgiQiTZDgGEEiSBBAkOSClMcMQtUkRQkSQfJYlSCJSBMk\nOEaQCBIEECS5IOUxg1A1SVGCRJA8ViVIItIECY4RJIIEAQRJLkh5zCBUTVKUIBEkj1UJkog0\nQYJjBIkgQQBBkgtSHjMIVZMUJUgEyWNVgiQiTZDgGEEiSBBAkOSClMcMQtUkRQkSQfJYlSCJ\nSBMkOEaQCBIEECS5IOUxg1A1SVGCRJA8ViVIItIECY4RJIIEAQRJLkh5zCBUTVKUIBEkj1UJ\nkog0QYJjBIkgQcCrgxRmfcHTOoRVXIm70gQpjxmEqkmK2g5SEcL0DQSJqvaK2g7S3avNBgmO\nyQYphNMmFLvy2u31x+o/m7ApT6uwOV8+W5/qk+dtCNtzc9VXse6XOdVnTvWJ0TekatTbtKWv\nl/SOLmX2RVgdvrlPggRh0kFqhrHdMEib6qWPVfVhe/2sqPPTXLpqrlrXpzrn5kx1zThIzYlN\n/VJ3Se+oLbNr3vRNktIEKY8ZhKpJikoHaX0uD6EYBmlbftTh+mg/q65Y11Hb1x92dcs3yevZ\nheoby/oWx8GJ87p+8XZJ/+L2W+GpPNZ38AxB8l7VfJDaGWsYpGZIO/c+O9XfiFbtFZvru25W\n3TWjIF1OhP4l/YvrMkXYfn57n2mCBMekg3T9ODrqPvRfD5fRbfz0YFzl+/K9o89q1FsNgzlF\nkCDs7YJUll+rUByf32eaIOUxg1A1SdGkQTrdC9JwtLu962bxaHe97vDdE3KC5L1qNkEqwsfl\nucA4SM3zgn39lGBXlh/1o4Jx2z982LBvn1Q8fNhQX1OEY/ml87ABjqUKUvMUen8vSJvBc+vw\nNQ1S/4n29MSTx9/1Ne3j7/3z+yRIEJYqSOWuqLr57s9Im7DpfpO6PpbTIPV/xzo6sXn6C9nm\nmuoLF9/kiNHOfVXjo10uCJL3qgRJRJogwTEzQQrh9jz8z05EIEgQRpDkgpTHDELVJEXNBOml\nCJL3qgRJRJogwTGCRJAggCDJBSmPGYSqSYoSJILksSpBEpEmSHCMIBEkCCBIckHKYwahapKi\nBIkgeaxKkESkCRIcI0gECQIIklyQ8phBqJqkKEEiSB6rEiQRaYIExwgSQYIAgiQXpDxmEKom\nKUqQCJLHqgRJRJogwTGCRJAggCDJBSmPGYSqSYoSJILksSpBEpEmSHCMIBEkCCBIckHKYwah\napKiBIkgeaxKkESkCRIcI0gECQIIklyQ8phBqJqkKEEiSB6rEiTAIoIECPAZJM8zCFWTFCVI\nxqtmdKs5VSVIgEUECRDgM0ieZxCqJilKkIxXzehWc6pKkACLCBIgwGeQPM8gVE1SlCAZr5rR\nreZUlSABFhEkQIDPIHmeQaiapChBMl41o1vNqSpBAiwiSIAAn0HyPINQNUlRgmS8aka3mlNV\nggRYRJAAAT6D5HkGoWqSoj6DFOCdeEtJF8xCmn/qJFUzutWcqhIkEZ53nKpJihIk41UzutWc\nqhIkEZ53nKpJihIk41UzutWcqhIkEZ53nKpJihIk41UzutWcqhIkEZ53nKpJihIk41UzutWc\nqhIkEZ53nKpJihIk41UzutWcqhIkEZ53nKpJivoMEiCMIAECCBIggCABAggSIIAgAQIIEiCA\nIAECCBIggCABAggSIIAgAQIIEiCAIAECCBIggCABAlwE6eeP8OPn7/svTM5JVF3+f9R+53Y2\n4fG5+KoR/5/yk6qbv1Is662q3LL+/ieEf349+IKLeAjS383y/3X3hck5iaq/Fu/4ndv5da0j\neKu3qstvdVr1Z/PCj9+y93qrKrisP5oXft09t4yDIP1P+PGr/PUj/M+dFybnRKr+CoXQrZb1\nZ+HROYGqi291WvVX+Od3/Z3uH9F77VWVW9afdbmfTbnltzrkIEg/w3+rj/8J6zsvTM6JVN0s\nqHe/aFXq70vLC95qr+riW51WLdqKdWHBe+1VlVvWH+H3pWbErVuJGeoAAAM9SURBVA45CFIR\n/i0H/3PWe2FyTqTqJmyEbrUMP8tLywveaq/q4lt9eD91Ycl7vVUVXNa25o8nX3AuB0EKof9f\nwxcm50SqFuG//1Q/wArcavlr/KLErfaqLr7VR/fzO/wte6+3qoLLWvvZ5HL5rY6+RuT7M6AR\npMbf8UWnL0o1Zxekhbf66H429agkHqSmquiy/ieEn0++4PyvEfn+DLw+SCH8p/of0Z/zJ5HX\nB2nxrT64n39/FPL32lUVXNZN8aP5uYgg/bHXB6n1e/4z1dcHqbXgVu9X/f3j74fnoqtePhFa\n1rL8p44kQfpjP8ZL1Xthck6k6sX8qndv5/KZ4K1+99nyqn//9fhcdNULoWWtI/kj5laHHASp\nfS7z7/j52r+3p3b/Ln68dL/qxfzNuXs73U8zYrc6vbkFfXSn6r9//f2v/L12VRff66PbaX+e\nXXqro1qR78/AuvlNwX/DzzsvTM6JVG1/TbFgc+7ezqVxBG+1V3Xxrd6p+t/uOYDkvd6qyi3r\ntdJfMbc65CBIr//Lhp/1tvxuf9UXV7R2aXnRv2zoqi6+1WnVf2/P0wTvtVdVblmbv2z4XdQ/\nI/GXDX/ur9tT07Z9ei/8tfTp77Oqv9s/5VrwP3KTor0DwVu9HSy/1UnVf8Ltb+Hk7rVXVXBZ\nf0h0wICHIP1u/r63OWyXsfdC71C46l9Lfg0/Kdo7ELzVUdVFtzqpGnpBkrvXcVWhZb1VWn6r\nAx6CBCRHkAABBAkQQJAAAQQJEECQAAEECRBAkAABBAkQQJAAAQQJEECQAAEECRBAkAABBAkQ\nQJAAAQQJEECQAAEECRBAkAABBAkQQJAAAQQJEECQAAEECRBAkAABBAkQQJAAAQQJEECQAAEE\nCRBAkAABBAkQQJAAAQQJEECQAAEECRBAkAABBAkQQJAAAQQJEECQAAEECRBAkAABBAkQQJAA\nAQQJEECQAAEECRBAkAABBAkQQJAAAQQJEECQAAEECRBAkAABBAkQQJAAAQQJEECQAAEECRBA\nkAABBAkQQJAAAQQJEECQAAEECRBAkAABBAkQQJAAAQQJEECQAAEECRBAkAABBAkQQJAAAQQJ\nEECQAAEECRDw/5tlZapZAGWWAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################################################################################################\n",
    "# Train the model using the optimal parameters from cross validation and calculate the in-sample confusionMatrix\n",
    "\n",
    "Optimalparams <- list(\"eta\" = head(CVResults$EtaValue, 1)[[1]], \n",
    "               \"max_depth\" = head(CVResults$MaxDepth, 1)[[1]], \n",
    "               \"objective\" = \"multi:softprob\",\n",
    "               \"eval_metric\" = \"mlogloss\",\n",
    "               \"num_class\" = numberOfClasses)\n",
    "\n",
    "Optimalnround <- head(CVResults$iter, 1)[[1]]\n",
    "\n",
    "# Train the final XGBoost model\n",
    "xgb.model <- xgb.train(Optimalparams, dtrain, Optimalnround)\n",
    "\n",
    "xgb.imp <- xgb.importance(model = xgb.model)\n",
    "xgb.plot.importance(xgb.imp)\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   1   2   3   4\n",
       "         1 290   0   0   0\n",
       "         2   6  84   0   0\n",
       "         3   0   1  13   0\n",
       "         4   0   2   2   9\n",
       "\n",
       "Overall Statistics\n",
       "                                          \n",
       "               Accuracy : 0.973           \n",
       "                 95% CI : (0.9522, 0.9864)\n",
       "    No Information Rate : 0.7273          \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.9375          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : NA              \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: 1 Class: 2 Class: 3 Class: 4\n",
       "Sensitivity            0.9797   0.9655  0.86667  1.00000\n",
       "Specificity            1.0000   0.9812  0.99745  0.98995\n",
       "Pos Pred Value         1.0000   0.9333  0.92857  0.69231\n",
       "Neg Pred Value         0.9487   0.9905  0.99491  1.00000\n",
       "Precision              1.0000   0.9333  0.92857  0.69231\n",
       "Recall                 0.9797   0.9655  0.86667  1.00000\n",
       "F1                     0.9898   0.9492  0.89655  0.81818\n",
       "Prevalence             0.7273   0.2138  0.03686  0.02211\n",
       "Detection Rate         0.7125   0.2064  0.03194  0.02211\n",
       "Detection Prevalence   0.7125   0.2211  0.03440  0.03194\n",
       "Balanced Accuracy      0.9899   0.9734  0.93206  0.99497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################################################################################################\n",
    "################## In-sample validation data predictions ##################\n",
    "xgb.pred.val <- predict(xgb.model, newdata = dval) # Note we train the optimal parameters on this data\n",
    "\n",
    "valConfMat <- matrix(xgb.pred.val, nrow = numberOfClasses,\n",
    "                          ncol = length(xgb.pred.val) / numberOfClasses) %>%\n",
    "  t() %>%\n",
    "  data.frame() %>%\n",
    "  mutate(label = y_val + 1,   # NOTE: We add the one back that we took away from earlier to the Y variable\n",
    "         val_predictions = max.col(., \"last\"))\n",
    "\n",
    "################## In-sample validation data confusion matrix ##################\n",
    "confusionMatrix(factor(valConfMat$val_predictions),\n",
    "                factor(valConfMat$label),\n",
    "                mode = \"everything\")\n",
    "\n",
    "# Approx 97% accuracy\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Make final predictions on the held out test set\n",
    "dtest <- xgb.DMatrix(data = as.matrix(test_outSample), missing = \"NaN\")\n",
    "xgb.pred.test <- predict(xgb.model, newdata = dtest)\n",
    "\n",
    "test_predictions <- matrix(xgb.pred.test, nrow = numberOfClasses,\n",
    "                     ncol = length(xgb.pred.test) / numberOfClasses) %>%\n",
    "  t() %>%\n",
    "  data.frame() %>%\n",
    "  mutate(predictions = max.col(., \"last\")) %>%\n",
    "  pull(predictions)\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "setwd(\"C:/Users/Matt/Desktop/Competitions/CarPopularity/\")\n",
    "write.csv(test_predictions, \"prediction.csv\")\n",
    "###################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
